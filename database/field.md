
金融
美国劳工部统计局官方发布数据
房地产公司 Zillow 公开美国房地产历史数据
沪深股票除权除息、配股增发全量数据，截止 2016.12.31
上证主板日线数据，截止 2017.05.05，原始价、前复权价、后复权价，1260支股票
深证主板日线数据，截止 2017.05.05，原始价、前复权价、后复权价，466支股票
深证中小板日线数据，截止 2017.05.05，原始价、前复权价、后复权价，852支股票
深证创业板日线数据，截止 2017.05.05，原始价、前复权价、后复权价，636支股票
上证A股日线数据，1999.12.09至 2016.06.08，前复权，1095支股票
深证A股日线数据，1999.12.09至 2016.06.08，前复权，1766支股票
深证创业板日线数据，1999.12.09 至2016.06.08，前复权，510支股票
MT4平台外汇交易历史数据
Forex平台外汇交易历史数据
几组外汇交易逐笔（Ticks）数据
美国股票新闻数据【Kaggle数据】
美国医疗保险市场数据【Kaggle数据】
美国金融客户投诉数据【Kaggle数据】
Lending Club 网贷违约数据【Kaggle数据】
信用卡欺诈数据【Kaggle数据】
美国股票数据XBRL【Kaggle数据】
纽约股票交易所数据【Kaggle数据】
贷款违约预测竞赛数据【Kaggle竞赛】
Zillow 网站房地产价值预测竞赛数据【Kaggle竞赛】
Sberbank 俄罗斯房地产价值预测竞赛数据【Kaggle竞赛】
Homesite 保险定价竞赛数据【Kaggle竞赛】
Winton 股票回报率预测竞赛数据【Kaggle竞赛】
房屋租赁信息查询次数预测竞赛【Kaggle竞赛】


交通
2013年纽约出租车行驶数据
2013年芝加哥出租车行驶数据
Udacity自动驾驶数据
纽约Uber 接客数据 【Kaggle数据】
英国车祸数据（2005-2015）【Kaagle数据】
芝加哥汽车超速数据【Kaggle数据】
KITTI 自动驾驶任务数据【数据太大仅有部分】
Cityscapes 场景标注数据【数据太大仅有部分】
德国交通标志识别数据
交通信号识别数据
芝加哥Divvy共享自行车骑行数据（2013年至今）
美国查塔努加市共享单车骑行数据
Capital 共享单车骑行数据
Bay Area 共享单车骑行数据
Nice Ride 共享单车骑行数据
花旗银行共享单车骑行数据
运用卫星数据跟踪亚马逊热带雨林中的人类轨迹竞赛【Kaggle竞赛】
纽约出租车管理委员会官方的乘车数据（2009年-2016年）

商业
Airbnb 开放的民宿信息和住客评论数据
Amazon 食品评论数据【Kaggle数据】
Amazon 无锁手机评论数据【Kaggle数据】
美国视频游戏销售和评价数据【Kaggle数据】
Kaggle 各项竞赛情况数据【Kaggle数据】
Bosch 生产流水线降低次品率竞赛数据【Kaggle竞赛】
预测公寓租金竞赛数据
广告点击预测竞赛数据
餐厅营业收入预测建模竞赛
银行产品推荐竞赛数据
网站用户推荐点击预测竞赛数据
在线广告实时竞价数据【Kaggle数据】
购物车商品关联竞赛数据【Kaggle竞赛】
Airbnb 新用户的民宿预定预测竞赛数据【Kaggle竞赛】
Yelp 点评网站公开数据
KKBOX 音乐用户续订预测竞赛【Kaggle竞赛】
Grupo Bimbo 面包店库存和销量预测竞赛【Kaggle竞赛】


一、图像数据集
1.MNIST
https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/
640?wx_fmt=png&wxfrom=5&wx_lazy=1

MNIST是最受欢迎的深度学习数据集之一，这是一个手写数字数据集，包含一组60,000个示例的训练集和一个包含10,000个示例的测试集。这是一个很好的数据库，用于在实际数据中尝试学习技术和深度识别模式，同时可以在数据预处理中花费最少的时间和精力。

大小： 50 MB

记录数量： 70,000张图片被分成了10个组。

SOTA： Capsules之间的动态路由

https://arxiv.org/pdf/1710.09829.pdf

2.MS-COCO
http://cocodataset.org/#home

640?wx_fmt=png

COCO是一个大型的、丰富的物体检测，分割和字幕数据集。它有几个特点：

对象分割；

在上下文中可识别；

超像素分割；

330K图像（> 200K标记）；

150万个对象实例；

80个对象类别；

91个类别；

每张图片5个字幕；

有关键点的250,000人；

大小：25 GB（压缩）

记录数量： 330K图像、80个对象类别、每幅图像有5个标签、25万个关键点。

SOTA：Mask R-CNN：https://arxiv.org/pdf/1703.06870.pdf

3.ImageNet
http://www.image-net.org/
640?wx_fmt=png

ImageNet是根据WordNet层次结构组织的图像数据集。WordNet包含大约100,000个单词，ImageNet平均提供了大约1000个图像来说明每个单词。

大小：150GB

记录数量：总图像是大约是1,500,000，每个都有多个边界框和相应的类标签。

SOTA：深度神经网络的聚合残差变换。

https://arxiv.org/pdf/1611.05431.pdf

4.Open Images数据集
https://github.com/openimages/dataset

640?wx_fmt=png

该数据集是一个包含近900万个图像URL的数据集，这些图像跨越了数千个类的图像级标签边框并且进行了注释。该数据集包含9,011,219张图像的训练集，41,260张图像的验证集以及125,436张图像的测试集。

大小：500 GB（压缩）

记录数量：9,011,219张超过5k标签的图像

SOTA：Resnet 101图像分类模型（在V2数据上训练）：模型检查点，检查点自述文件，推理代码。

5.VisualQA
http://www.visualqa.org/
640?wx_fmt=png

VQA是一个包含相关图像的开放式问题的数据集，这些问题需要理解视野和语言。这个数据集的一些有趣的特点是：

265,016张图片（COCO和抽象场景）；

每张图片至少有3个问题（平均5.4个问题）；

每个问题有10个基本事实答案；

每个问题有3个似乎合理（但可能不正确）的答案；

自动评估指标。

大小：25 GB（压缩）

记录数量：265,016张图片，每张图片至少3个问题，每个问题10个基本事实答案。

SOTA：视觉问答的技巧和诀窍：从2017年的挑战中学习

6.街景房屋号码（SVHN）
http://ufldl.stanford.edu/housenumbers/
640?wx_fmt=png

这是用于开发对象检测算法的真实世界的图像数据集，它需要最少的数据预处理。它与本列表中提到的MNIST数据集类似，但具有更多标签数据（超过600,000个图像），这些数据是从谷歌街景中查看的房屋号码中收集的。

大小：2.5 GB

记录数量：6,30,420张图片被分布在10个类中。

SOTA：虚拟对抗训练的分布平滑

7.CIFAR-10
http://www.cs.toronto.edu/~kriz/cifar.html
640?wx_fmt=png

该数据集是图像分类的另一个数据集，它由10个类的60,000个图像组成（每个类在上面的图像中表示为一行）。总共有50,000个训练图像和10,000个测试图像。数据集分为6个部分：5个训练批次和1个测试批次，每批有10,000个图像。

大小：170 MB

记录数量：60,000张图片被分为10个类。

SOTA：ShakeDrop正则化

8.Fashion--MNIST
https://github.com/zalandoresearch/fashion-mnist
640?wx_fmt=png

Fashion-MNIST包含60,000个训练图像和10,000个测试图像，它是一个类似MNIST的时尚产品数据库。开发人员认为MNIST已被过度使用，因此他们将其作为该数据集的直接替代品。每张图片都以灰度显示，并与10个类别的标签相关联。

大小：30 MB。

记录数量：70,000张图片被分为10个类。

SOTA：随机擦除数据增强

二、自然语言处理
9.IMDB评论 
http://ai.stanford.edu/~amaas/data/sentiment/
这是电影爱好者的梦幻数据集，它意味着二元情感分类，并具有比此领域以前的任何数据集更多的数据。除了训练和测试评估示例之外，还有更多未标记的数据供你使用。原始文本和预处理的单词格式包也包括在内。

大小：80 MB。

记录数量： 25,000个电影评论训练，25,000个测试

SOTA：学习结构化文本表示

10.二十个新闻组（Twenty Newsgroups）https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups
顾名思义，该数据集包含有关新闻组的信息。为了管理这个数据集，从20个不同的新闻组中获取了1000篇Usenet文章。这些文章具有典型特征，如主题行，签名和引号。

大小：20 MB

记录数量：来自20个新闻组的20,000条消息。

SOTA：用于文本分类的非常深的卷积网络，

11.Sentiment140
http://help.sentiment140.com/for-students/
Sentiment140是一个可用于情感分析的数据集。它是一个流行的数据集，它能让你的NLP旅程更加完美。情绪已经从数据中预先删除，最终的数据集具有以下6个特征：

推文的极性（polarity of the tweet）。

推文的ID。

推文的日期。

查询。

推文的文本。

大小：80 MB（压缩）。

记录数量：160,000条推文。

SOTA：评估最先进的情感数据集的最新情绪模型

12.WordNet
https://wordnet.princeton.edu/
在上面的ImageNet数据集中提到，WordNet是一个包含英文synsets的大型数据库。Synsets是同义词组，每个描述不同的概念。WordNet的结构使其成为NLP非常有用的工具。

大小：10 MB

记录数量：通过少量“概念关系”将117,000个同义词集与其他同义词集相关联。

SOTA：Wordnet：现状和前景

13.Yelp评论
https://www.yelp.com/dataset
这是Yelp为了学习目的而发布的一个开放数据集。它由数百万用户评论，商业属性和来自多个大都市地区的超过20万张照片组成。这是一个非常常用的全球NLP挑战数据集。

大小：2.66 GB JSON，2.9 GB SQL和7.5 GB照片（全部压缩）

记录数：5,200,000条评论，174,000条商业属性，20万张照片。

SOTA：细心卷积(Attentive Convolution)

14.维基百科语料库
http://nlp.cs.nyu.edu/wikipedia-data/
该数据集是维基百科全文的集合。它包含来自400多万篇文章的将近19亿字。这个强大的NLP数据集你可以通过单词，短语或段落本身的一部分进行搜索。

大小：20 MB。

记录数：4,400,000篇文章，19亿字。

SOTA：打破Softmax Bottelneck：高级RNN语言模型

15.博客作者身份语料库
http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm
此数据集包含从数千名博主收集的博客帖子，并且已从blogger.com收集。每个博客都作为一个单独的文件提供，每个博客至少包含200次常用英语单词。

大小：300 MB

记录数：681,288个帖子，超过1.4亿字。

SOTA：用于大规模作者归属的字符级和多通道卷积神经网络

16.欧洲语言的机器翻译数据集
http://statmt.org/wmt18/index.html
该数据集包含四种欧洲语言的训练数据，它存在的任务是改进当前的翻译方法。你训练以下任何语言对：

法语——英语；

西班牙语——英语；

德语——英语；

捷克语——英语。

大小：15 GB

记录数量：约30,000,000个句子及其翻译。

SOTA：Attention就是你所需要的

三、音频/语音数据集
17.免费口语数字数据集
https://github.com/Jakobovski/free-spoken-digit-dataset
此列表中的另一项是由MNIST数据集启发！这是为了解决识别音频样本中的口头数字的任务而创建的。这是一个开放的数据集，所以希望随着人们继续贡献更多样本，它会不断增长。目前，它包含以下特点：

3个扬声器；

1500个录音（每个扬声器每个数字50个）；

英语发音；

大小：10 MB。

记录数量：1500个音频样本。

SOTA：使用采样级CNN架构的基于原始波形的音频分类

18.免费音乐档案（FMA）
https://github.com/mdeff/fma
FMA是音乐分析的数据集，该数据集由full-length和HQ音频、预先计算的特征以及音轨和用户级元数据组成。它是一个开放数据集，用于评估MIR中的几个任务。以下是数据集连同其包含的csv文件列表：

tracks.csv：106,574首曲目的每首曲目元数据，如ID，标题，艺术家，流派，标签和播放次数。

genres.csv：163种风格的ID与他们的名字和父母（用于推断流派层次和顶级流派）。

features.csv：用librosa提取的共同特征 。

echonest.csv：由Echonest （现在的 Spotify）为13,129首音轨的子集提供的音频功能 。

大小：1000 GB

记录数量：约100,000 tracks

SOTA：学习从音频中识别音乐风格

19.舞厅（Ballroom）：http://mtg.upf.edu/ismir2004/contest/tempoContest/node5.html
该数据集包含舞厅跳舞音频文件，以真实音频格式提供了许多舞蹈风格的一些特征摘录。 以下是数据集的一些特征：

实例总数：698；

持续时间：约30秒；

总持续时间：约20940秒；

大小： 14GB（压缩）

记录数量：约700个音频样本

SOTA：考虑到不同类型音乐风格的多模型方法来打败追踪

20.百万歌曲数据集
https://labrosa.ee.columbia.edu/millionsong/
在百万歌曲数据集是音频功能和元数据的一百万当代流行音乐曲目可自由可用的集合。 其目的是：

鼓励对扩大到商业规模的算法进行研究；

为评估研究提供参考数据集；

作为使用API创建大型数据集的捷径（例如Echo Nest的）；

帮助新研究人员在MIR领域开始工作；

数据集的核心是一百万首歌曲的特征分析和元数据。该数据集不包含任何音频，只包含派生的功能。示例音频可以通过使用哥伦比亚大学提供的代码从7digital等服务中获取。

大小： 280 GB

记录数量：一百万首歌曲！

SOTA：百万歌曲数据集挑战推荐系统的初步研究

21.LibriSpeech
http://www.openslr.org/12/
该数据集是包含大约1000小时的英语语音的大型语料库。这些数据来自LibriVox项目的有声读物。它已被分割并正确对齐，如果你正在寻找一个起点，请查看已准备好的声学模型，这些模型在kaldi-asr.org和语言模型上进行了训练，适合评估，网址为：http://www.openslr.org/11/。

大小：60 GB

记录数： 1000小时的演讲。

SOTA：基于信件的语音识别与门控通信

22.VoxCeleb
http://www.robots.ox.ac.uk/~vgg/data/voxceleb/
VoxCeleb是一个大型的说话人识别数据集。它包含约1,200名来自YouTube视频的约10万个话语，数据大部分是性别平衡的（男性占55％）。名人跨越不同的口音，职业和年龄，开发和测试集之间没有重叠。对于隔离和识别哪个超级巨星来说，这是一个有趣的用例。

大小： 150 MB

记录数： 1,251位名人的100,000条话语。

SOTA：VoxCeleb：一个大型说话人识别数据集

四、数据集的问题实践
23.Twitter情绪分析
https://datahack.analyticsvidhya.com/contest/practice-problem-twitter-sentiment-analysis/
仇恨以种族主义和性别歧视为形式的言论已成为麻烦，重要的是将这类推文与其他人分开。在这个实践问题中，我们提供既有正常又有仇恨推文的Twitter数据。你作为数据科学家的任务是确定推文是仇恨推文，哪些不是。

大小： 3 MB。

记录数量： 31,962条推文。

24.印度演员的年龄检测
https://datahack.analyticsvidhya.com/contest/practice-problem-age-detection/
对于任何深度学习爱好者来说，这是一个令人着迷的挑战。该数据集包含数千个印度演员的图像，你的任务是确定他们的年龄。所有图像都是手动选择的，并从视频帧中剪切，导致尺度，姿势，表情，照度，年龄，分辨率，遮挡和化妆的高度可变性。

大小： 48 MB（压缩）。

记录数：训练集中的19,906幅图像和测试集中的6636幅图像。

SOTA：深入学习 - 解决年龄检测问题

25.城市声音分类
https://datahack.analyticsvidhya.com/contest/practice-problem-urban-sound-classification/
这个数据集包含超过8000个来自10个不同城市声音摘录。这个实践问题旨在向你介绍常见分类方案中的音频处理。

大小：训练集 - 3 GB（压缩），测试集 - 2 GB（压缩）

记录数： 来自10个城市的8732个声音标注的声音片段（<= 4s）



CN-Celeb 无约束条件说话人识别的中文语音数据集
原创海上机械师 最后发布于2020-02-24 22:59:34 阅读数 448  收藏
展开
CN-Celeb 无约束条件说话人识别的中文语音数据集
数据源：http://www.openslr.org/82/

项目源：http://cslt.riit.tsinghua.edu.cn/mediawiki/index.php/CN-Celeb

文献：Fan Y, Kang J, Li L et al. CN-CELEB: a challenging Chinese speaker recognition dataset. arXiv preprint arXiv:1911.01799, 2019.

摘要
目的：研究无约束条件下的自动说话人识别，换句话说，speaker recognition in the wild。
数据与方法：建立了CN-Celeb数据集，该数据集包含130,000条语音段，1000位中国名人，11种语音体裁，短时语音段，共计274小时。CN-Celeb在i-vector/PLDA与x-vector/PLDA进行评测，并与VoxCeleb数据对比。
结果：在i-vector/PLDA与x-vector/PLDA两个算法上，CN-Celeb上EER高于10%，VoxCeleb上EER低于10%。
结论：CN-Celeb数据与VoxCeleb数据的区别显著；对于现阶段的说话人识别算法来说，CN-Celeb数据集更具挑战。

1. 引言
数十年的研究极大地提升了说话人识别系统的性能，然而无约束条件的说话人识别仍然难以达到可靠的水平。不确定的因素主要来自两方面，一是外在因素，二是内在因素，具体地，文本无关、多信道、环境噪声、说话人风格、生理健康状态。

传统的因子分析方法与概率线性可区分性分析、最新的深度学习方法在受约束数据集上的说话人识别性能表现良好，然而这些数据集没有充分体现出丰富的声学条件，例如DARPA、SWITCHBOARD、NIST SRE与Voxceleb。

研究无约束条件的说话人识别问题，“In The Wild”数据集是重要的基础。基于VoxCeleb数据集提供的自动化数据采集流程，清华大学收集了一份大规模的中文语音数据集CN-Celeb，该数据集有3个特点：

CN-Celeb专注中国名人，包含130,000+语音段，来自1000位。
CN-Celeb包含11种语音体裁，例如娱乐，访问，唱歌，戏剧，电影，视频博客，现场直播，演讲，戏剧，朗诵和广告，相比较VoxCeleb只是访问的语音，更具有无约束条件的代表性。
CN-Celeb涉及人工检测，语音段的准确性更高。
2. CN-Celeb 数据集
CN-Celeb数据集具有三个特性：专注中国人、复杂的体裁、质量保证。数据统计结果如下：

表1. 语音体裁分布
体裁	说话人数量	语音段数量	小时数
娱乐	483	22,064	33.67
访问	780	59,317	135.77
唱歌	318	12,551	28.83
戏剧	69	4,245	4.95
电影	62	2,749	2.20
视频博客	41	1,894	4.15
现场直播	129	8,747	16.35
演讲	122	8,401	36.22
戏剧	160	7,274	6.43
朗诵	41	2,747	4.98
广告	17	120	0.18
共计	1,000	130,109	273.73
表2. 语音段长度的分布
长度(秒)	语音段数量	占比
<2	41,658	32.0%
2-5	38,629	30.0%
5-10	23,497	18.0%
10-15	10,687	8.0%
15-20	5,334	4.0%
20-25	3,218	2.5%
25-30	1,991	1.5%
>30	5,095	4%
CN-Celeb与VoxCeleb数据统计的对比结果如下表所示，两者的差别如下：

更多的真实噪声，例如环境噪声、背景babbing、音乐、欢呼声与小声；
强的、覆盖说话人的背景，特别是戏剧与电影场景；
多数说话人有不同的说话流派，使得说话风格差异显著；
不同时间与不同设备记录的语音；
多数语音是短时的。
表3. CN-Celeb与VoxCeleb的比较
CN-Celeb	VocCeleb
数据源	bilibili.com	youtube.com
语言	中文	英语为主
体裁	11	访问为主
人数	1,000	7,363
语音数	130,109	1,281,762
小时数	274	2,794
人工检查	是	否
论文提及了获取数据的步骤，是一种两阶段的方式：

自动提取分段，

人工筛选有效分段，其中人工删选的效率为 1 小时内检查 1 小时的语音。

备注：个人知识水平有些，对自动提取部分的人脸检测、追踪、语音对齐等技术不熟悉，故不做介绍。

3. 说话人识别的实验
实验涉及的数据、方法及其设定如下：

数据：
评测集：SITW，来自VoxCeleb1；CN-Celeb(E)，共200人。
训练集：VoxCeleb，由VoxCeleb1与VoxCeleb2组成，除去SITW部分，1,236,567段语音；CN-Celeb(T)，共800人。
挑选的评测集：SITW(S)，将SITW重新分段，使其时长与CN-Celeb(E)相似。
挑选的训练集：VoxCeleb(L)，来自VoxCeleb，800人，与CN-Celeb(T)人数上相同。
方法及其设定：
i-vector：MFCC + CMN + VAD + UBM + i-vector + LDA + PLDA
x-vector：TDNN + LDA + PLDA
前端模型：i-vector与x-vector
后端模型：LDA与PLDA
实验结果分为两部分：

基准实验结果，i-vector与x-vector学习VoxCeleb数据集之后，在SITW、SITW(S)、CN-Celeb(E)上的性能评估，见表4所示。
不同训练数据的评估结果，当训练集为VoxCeleb、VoxCeleb(L)或CN-Celeb(T)，在SITW(S)、CN-Celeb(E)上的性能评估，见表5所示。
表4. i-vector与x-vector在三个评测数据集上的EER
训练集	评测集
系统	前端	后端	SITW	SITW(S)	CN-Celeb(E)
i-vector	VoxCeleb	VoxCeleb	5.30	7.30	19.05
x-vector	VoxCeleb	VoxCeleb	3.75	4.78	15.52
表5. 不同数据设定的EER
训练集	评测集
系统	前端	后端	SITW(S)	CN-Celeb(E)
i-vector	VoxCeleb	VoxCeleb(L)	8.34	17.43
CN-Celeb(T)	CN-Celeb(T)	14.87	14.24
VoxCeleb	CN-Celeb(T)	12.96	15.00
CN-Celeb(T)	VoxCeleb(L)	11.34	15.50
x-vector	VoxCeleb	VoxCeleb(L)	5.93	13.64
CN-Celeb(T)	CN-Celeb(T)	15.23	14.78
VoxCeleb	CN-Celeb(T)	10.72	11.99
CN-Celeb(T)	VoxCeleb(L)	12.68	15.62
作者：王瑞 同济大学 计算机系博士研究生

邮箱：rwang@tongji.edu.cn

CSDN：https://blog.csdn.net/i_love_home

Github：https://github.com/mechanicalsea

点赞 1
————————————————
版权声明：本文为CSDN博主「海上机械师」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/i_love_home/article/details/104487814
